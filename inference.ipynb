{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sharded model initialized.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sharded model initialized.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import Mesh\n",
    "from jax.sharding import NamedSharding\n",
    "\n",
    "import flax\n",
    "\n",
    "from rich import print\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch_to_flax import torch_to_flax\n",
    "from model_flax_sharded import get_partition_rules, Qwen2Config, Qwen2ForCausalLM\n",
    "\n",
    "# Set this environment variable before importing JAX.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9375\"\n",
    "\n",
    "\n",
    "def init_sharded_model():\n",
    "    \"\"\"Initialize a model with parameters on CPU then shard them to GPU after checkpoint loading.\"\"\"\n",
    "    # Create config and model\n",
    "    config = Qwen2Config()\n",
    "    model = Qwen2ForCausalLM(config=config)\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    input_shape = (1, 32)\n",
    "\n",
    "    # Force initialization on CPU to avoid duplicate GPU allocations\n",
    "    with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "        try:\n",
    "            params = model.init(rng, jnp.ones(input_shape, dtype=jnp.int4))\n",
    "        except Exception as e:\n",
    "            params = model.init(rng, jnp.ones(input_shape, dtype=jnp.int32))\n",
    "\n",
    "\n",
    "    # Get available JAX devices and create mesh\n",
    "    devices = jax.devices()\n",
    "    device_mesh = np.array(devices).reshape(-1)  # 1D mesh\n",
    "    mesh = Mesh(device_mesh, (\"mp\",))\n",
    "\n",
    "    partition_rules = get_partition_rules()\n",
    "\n",
    "    # Helper to match a parameter path to a partition spec\n",
    "    def get_spec(path: str):\n",
    "        for rule_path, spec in partition_rules:\n",
    "            if rule_path in path:\n",
    "                return spec\n",
    "        return None\n",
    "\n",
    "    # Build sharding specs for each param in the tree\n",
    "    def create_sharding_specs(param_tree):\n",
    "        def assign_spec(path, value):\n",
    "            # Convert tuple path into a slash-joined string\n",
    "            path_str = \"/\".join(str(p) for p in path)\n",
    "            matched_spec = get_spec(path_str)\n",
    "            if matched_spec is None:\n",
    "                return NamedSharding(mesh, None)\n",
    "            return NamedSharding(mesh, matched_spec)\n",
    "\n",
    "        return jax.tree_util.tree_map_with_path(assign_spec, param_tree)\n",
    "\n",
    "    sharding_specs = create_sharding_specs(params)\n",
    "\n",
    "    # Load the parameters from the file\n",
    "    try:\n",
    "        with open(\"flax_params.msgpack\", \"rb\") as f:\n",
    "            loaded_bytes = f.read()\n",
    "            loaded_params = {\n",
    "                \"params\": flax.serialization.from_bytes(params[\"params\"], loaded_bytes)\n",
    "            }\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Running conversion...\")\n",
    "        torch_to_flax()\n",
    "        with open(\"flax_params.msgpack\", \"rb\") as f:\n",
    "            loaded_bytes = f.read()\n",
    "            loaded_params = {\n",
    "                \"params\": flax.serialization.from_bytes(params[\"params\"], loaded_bytes)\n",
    "            }\n",
    "\n",
    "\n",
    "    del params\n",
    "    # After loading 'loaded_params' from disk (which might be plain NumPy arrays)\n",
    "    sharded_params = jax.tree_util.tree_map(\n",
    "        lambda x, spec: jax.device_put(x, spec), loaded_params, sharding_specs\n",
    "    )\n",
    "\n",
    "    return model, sharded_params\n",
    "\n",
    "model, sharded_params = init_sharded_model()\n",
    "print(\"Sharded model initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generating tokens<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Generating tokens\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Decoded text: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #000000; text-decoration-color: #000000\">｜begin▁of▁sentence｜&gt;What is </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">? &lt;think&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">To solve </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\"> plus </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">, I start by identifying the numbers involved, which are </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\"> and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Next, I add these two numbers together by combining them: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\"> and </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\"> make </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #000000; text-decoration-color: #000000\">.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Therefore, the final answer is </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #000000; text-decoration-color: #000000\">.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">think</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "To solve the addition \\<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\\<span style=\"font-weight: bold\">)</span>, follow these easy steps:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Identify the numbers to add:**\n",
       "   <span style=\"font-weight: bold\">[</span>\n",
       "   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> \\quad \\text<span style=\"font-weight: bold\">{</span>and<span style=\"font-weight: bold\">}</span> \\quad <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Decoded text: \u001b[1m<\u001b[0m\u001b[39m｜begin▁of▁sentence｜>What is \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m? <think>\u001b[0m\n",
       "\u001b[39mTo solve \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m plus \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m, I start by identifying the numbers involved, which are \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m and \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m.\u001b[0m\n",
       "\n",
       "\u001b[39mNext, I add these two numbers together by combining them: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m and \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m make \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m.\u001b[0m\n",
       "\n",
       "\u001b[39mTherefore, the final answer is \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m.\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mthink\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "To solve the addition \\\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m + \u001b[1;36m4\u001b[0m\\\u001b[1m)\u001b[0m, follow these easy steps:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Identify the numbers to add:**\n",
       "   \u001b[1m[\u001b[0m\n",
       "   \u001b[1;36m3\u001b[0m \\quad \\text\u001b[1m{\u001b[0mand\u001b[1m}\u001b[0m \\quad \u001b[1;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "prompt = \"What is 3 + 4? <think>\\n\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = jnp.array(inputs[\"input_ids\"].numpy())\n",
    "# Generate\n",
    "print(\"Generating tokens...\")\n",
    "output = model.generate(\n",
    "    sharded_params,\n",
    "    input_ids,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    prng_key=jax.random.PRNGKey(0),\n",
    ")\n",
    "\n",
    "# Decode using your tokenizer\n",
    "decoded = tokenizer.decode(np.array(output[0]))\n",
    "print(\"Decoded text:\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
